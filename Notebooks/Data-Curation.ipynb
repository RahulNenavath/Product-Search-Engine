{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6417f41",
   "metadata": {},
   "source": [
    "## Dataset Processing Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8488d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "project_dir = Path(os.getcwd()).parent\n",
    "data_dir = project_dir / \"Data\" / \"RAW\"\n",
    "processed_dir = project_dir / \"Data\" / \"PROCESSED\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70c56c",
   "metadata": {},
   "source": [
    "### Links to Datasets:\n",
    "* Amazon ESCI: [Github](https://github.com/amazon-science/esci-data)\n",
    "* WANDS: [Github](https://github.com/wayfair/WANDS/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433016fe",
   "metadata": {},
   "source": [
    "### Amazon ESCI's dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec9b0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_path = data_dir / \"shopping_queries_dataset_examples.parquet\"\n",
    "products_path = data_dir / \"shopping_queries_dataset_products.parquet\"\n",
    "\n",
    "examples_df = pd.read_parquet(examples_path)\n",
    "products_df = pd.read_parquet(products_path)\n",
    "\n",
    "amz_esci_df = pd.merge(\n",
    "    examples_df,\n",
    "    products_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"product_id\",\n",
    "    right_on=\"product_id\",\n",
    "    suffixes=(\"_example\", \"_product\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef701cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged ESCI data shape: (613016, 11)\n",
      "Columns: ['example_id', 'query', 'query_id', 'product_id', 'esci_label', 'split', 'product_title', 'product_description', 'product_bullet_point', 'product_brand', 'product_color']\n"
     ]
    }
   ],
   "source": [
    "print(f'Merged ESCI data shape: {amz_esci_df.shape}')\n",
    "print(f'Columns: {amz_esci_df.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f9b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only small version and US locale - from dataset paper\n",
    "amz_esci_df = amz_esci_df[amz_esci_df['small_version'] == 1].drop(['small_version', 'large_version'], axis=1)\n",
    "amz_esci_df = amz_esci_df[amz_esci_df['product_locale_example'] == 'us'].drop(['product_locale_example', 'product_locale_product'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only train and test splits\n",
    "amz_esci_train_df_raw = amz_esci_df[amz_esci_df['split'] == 'train'].drop(['split'], axis=1)\n",
    "amz_esci_test_df_raw = amz_esci_df[amz_esci_df['split'] == 'test'].drop(['split'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d97532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon ESCI train shape: (427655, 10)\n",
      "Amazon ESCI test shape: (185361, 10)\n",
      "Amazon ESCI train queries count: 20888\n",
      "Amazon ESCI test queries count: 8956\n"
     ]
    }
   ],
   "source": [
    "print(f'Amazon ESCI train shape: {amz_esci_train_df_raw.shape}')\n",
    "print(f'Amazon ESCI test shape: {amz_esci_test_df_raw.shape}')\n",
    "\n",
    "print(f'Amazon ESCI train queries count: {amz_esci_train_df_raw[\"query\"].nunique()}')\n",
    "print(f'Amazon ESCI test queries count: {amz_esci_test_df_raw[\"query\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883c12b",
   "metadata": {},
   "source": [
    "### WAND's dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468d7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.read_csv(data_dir / 'product.csv', sep='\\t')\n",
    "query_df = pd.read_csv(data_dir / 'query.csv', sep='\\t')\n",
    "label_df = pd.read_csv(data_dir / 'label.csv', sep='\\t')\n",
    "\n",
    "x = pd.merge(query_df, label_df, on='query_id', how='inner')\n",
    "y = pd.merge(x, product_df, on='product_id', how='inner')\n",
    "wands_df = y.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281676ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged WANDs data shape: (233448, 13)\n",
      "Columns: ['query_id', 'query', 'query_class', 'product_id', 'label', 'product_name', 'product_class', 'category hierarchy', 'product_description', 'product_features', 'rating_count', 'average_rating', 'review_count']\n"
     ]
    }
   ],
   "source": [
    "print(f'Merged WANDs data shape: {wands_df.shape}')\n",
    "print(f'Columns: {wands_df.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c2e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.3,\n",
    "    seed: int = 42\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    qids = df[\"query_id\"].astype(str).unique()\n",
    "    qids_shuffled = pd.Series(qids).sample(frac=1.0, random_state=seed).tolist()\n",
    "    cut = int(len(qids_shuffled) * (1 - test_size))\n",
    "\n",
    "    train_qids = set(qids_shuffled[:cut])\n",
    "    test_qids = set(qids_shuffled[cut:])\n",
    "    \n",
    "    train_df = df[df[\"query_id\"].astype(str).isin(train_qids)].reset_index(drop=True)\n",
    "    test_df = df[df[\"query_id\"].astype(str).isin(test_qids)].reset_index(drop=True)\n",
    "    \n",
    "    assert len(set(train_df[\"query_id\"].astype(str)).intersection(set(test_df[\"query_id\"].astype(str)))) == 0, \"Train and test sets have overlapping query_ids\"\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22b8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "wands_train_df_raw, wands_test_df_raw = train_test_split(wands_df, test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a404b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDS train shape: (162789, 13)\n",
      "WANDS test shape: (70659, 13)\n",
      "WANDs train queries count: 336\n",
      "WANDs test queries count: 144\n"
     ]
    }
   ],
   "source": [
    "print(f'WANDS train shape: {wands_train_df_raw.shape}')\n",
    "print(f'WANDS test shape: {wands_test_df_raw.shape}')\n",
    "\n",
    "print(f'WANDs train queries count: {wands_train_df_raw[\"query\"].nunique()}')\n",
    "print(f'WANDs test queries count: {wands_test_df_raw[\"query\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feb38516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_esci_artifacts(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    query_id_col: str = \"query_id\",\n",
    "    query_col: str = \"query\",\n",
    "    product_id_col: str = \"product_id\",\n",
    "    label_col: str = \"esci_label\",\n",
    "    metadata_cols: Optional[List[str]] = None,\n",
    "    keep_irrelevant: bool = False,\n",
    "    top_k: Optional[int] = 40,\n",
    "    query_prefix: str = \"amz_\",\n",
    "    product_prefix: str = \"amz_\",\n",
    "    grading: Optional[Dict[str, float]] = None,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, float]], Dict[str, Dict[str, Any]], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ESCI -> (qrels_df, qrels_dict, product_store, query_table_df)\n",
    "\n",
    "    qrels_df: query_id | ranked_product_ids (List[str])  (sorted by gain desc)\n",
    "    qrels_dict: {query_id: {product_id: gain}} (graded)\n",
    "    product_store: {product_id: metadata}\n",
    "    query_table_df: query_id | query\n",
    "\n",
    "    Default grading (configurable):\n",
    "      Exact:3, Substitute:2, Complement:1, Irrelevant:0\n",
    "    \"\"\"\n",
    "    if metadata_cols is None:\n",
    "        metadata_cols = [\n",
    "            \"product_title\",\n",
    "            \"product_description\",\n",
    "            \"product_bullet_point\",\n",
    "            \"product_brand\",\n",
    "            \"product_color_name\",\n",
    "        ]\n",
    "    if grading is None:\n",
    "        grading = {\n",
    "            \"EXACT\": 3.0, \"E\": 3.0,\n",
    "            \"SUBSTITUTE\": 2.0, \"S\": 2.0,\n",
    "            \"COMPLEMENT\": 1.0, \"C\": 1.0,\n",
    "            \"IRRELEVANT\": 0.0, \"I\": 0.0,\n",
    "        }\n",
    "\n",
    "    required = {query_id_col, query_col, product_id_col, label_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"ESCI df missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    metadata_cols = [c for c in metadata_cols if c in df.columns]\n",
    "    work = df[[query_id_col, query_col, product_id_col, label_col] + metadata_cols].copy()\n",
    "\n",
    "    # Prefix IDs\n",
    "    work[query_id_col] = query_prefix + work[query_id_col].astype(str)\n",
    "    work[product_id_col] = product_prefix + work[product_id_col].astype(str)\n",
    "\n",
    "    # Label -> gain\n",
    "    work[label_col] = work[label_col].astype(str).str.strip().str.upper()\n",
    "    work[\"gain\"] = work[label_col].map(grading)\n",
    "    work = work.dropna(subset=[\"gain\", query_id_col, product_id_col, query_col])\n",
    "\n",
    "    if not keep_irrelevant:\n",
    "        work = work[work[\"gain\"] > 0.0]\n",
    "\n",
    "    # dedupe by (qid,pid) keeping max gain deterministically\n",
    "    work = (\n",
    "        work.sort_values([\"gain\"], ascending=False, kind=\"mergesort\")\n",
    "            .drop_duplicates(subset=[query_id_col, product_id_col], keep=\"first\")\n",
    "    )\n",
    "\n",
    "    # order within query\n",
    "    work = work.sort_values(\n",
    "        by=[query_id_col, \"gain\", product_id_col],\n",
    "        ascending=[True, False, True],\n",
    "        kind=\"mergesort\",\n",
    "    )\n",
    "\n",
    "    if top_k is not None:\n",
    "        work = work.groupby(query_id_col, sort=False, as_index=False).head(top_k)\n",
    "\n",
    "    qrels_df = (\n",
    "        work.groupby(query_id_col, sort=False)[product_id_col]\n",
    "            .apply(list)\n",
    "            .reset_index(name=\"ranked_product_ids\")\n",
    "            .rename(columns={query_id_col: \"query_id\"})\n",
    "    )\n",
    "\n",
    "    qrels_dict: Dict[str, Dict[str, float]] = {}\n",
    "    for qid, sub in work.groupby(query_id_col, sort=False):\n",
    "        qrels_dict[str(qid)] = {str(pid): float(g) for pid, g in zip(sub[product_id_col], sub[\"gain\"])}\n",
    "\n",
    "    # product_store (dedupe by product_id)\n",
    "    prod = (\n",
    "        work.sort_values([product_id_col], kind=\"mergesort\")\n",
    "            .drop_duplicates(subset=[product_id_col], keep=\"first\")\n",
    "    )\n",
    "    product_store: Dict[str, Dict[str, Any]] = {}\n",
    "    for _, row in prod.iterrows():\n",
    "        pid = row[product_id_col]\n",
    "        product_store[pid] = {c: row[c] for c in metadata_cols}\n",
    "\n",
    "    query_table_df = (\n",
    "        work[[query_id_col, query_col]]\n",
    "        .drop_duplicates(subset=[query_id_col], keep=\"first\")\n",
    "        .rename(columns={query_id_col: \"query_id\", query_col: \"query\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return qrels_df, qrels_dict, product_store, query_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc209f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wands_artifacts(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    query_id_col: str = \"query_id\",\n",
    "    query_col: str = \"query\",\n",
    "    product_id_col: str = \"product_id\",\n",
    "    label_col: str = \"label\",\n",
    "    keep_irrelevant: bool = False,\n",
    "    top_k: Optional[int] = 40,\n",
    "    query_prefix: str = \"wands_\",\n",
    "    product_prefix: str = \"wands_\",\n",
    "    grading: Optional[Dict[str, float]] = None,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, Dict[str, float]], Dict[str, Dict[str, Any]], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    WANDS -> (qrels_df, qrels_dict, product_store, query_table_df)\n",
    "\n",
    "    Default grading (configurable):\n",
    "      Exact:2 (or 3), Partial:1, Irrelevant:0\n",
    "    \"\"\"\n",
    "    if grading is None:\n",
    "        grading = {\"EXACT\": 2.0, \"PARTIAL\": 1.0, \"IRRELEVANT\": 0.0}\n",
    "    \n",
    "    # Prefix IDs (collision-proof)\n",
    "    df[product_id_col] = product_prefix + df[product_id_col].astype(str)\n",
    "    df[query_id_col] = query_prefix + df[query_id_col].astype(str)\n",
    "\n",
    "    # product_store: all columns; NaN->None for JSON friendliness\n",
    "    product_store: Dict[str, Dict[str, Any]] = {}\n",
    "    for _, r in df.iterrows():\n",
    "        pid = str(r[product_id_col])\n",
    "        product_store[pid] = {k: (None if pd.isna(v) else v) for k, v in r.items()}\n",
    "\n",
    "    query_table_df = (\n",
    "        df[[query_id_col, query_col]]\n",
    "        .drop_duplicates(subset=[query_id_col], keep=\"first\")\n",
    "        .rename(columns={query_id_col: \"query_id\", query_col: \"query\"})\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    work = df[[query_id_col, product_id_col, label_col]].copy()\n",
    "    work[label_col] = work[label_col].astype(str).str.strip().str.upper()\n",
    "    work[\"gain\"] = work[label_col].map(grading)\n",
    "    work = work.dropna(subset=[\"gain\", query_id_col, product_id_col])\n",
    "\n",
    "    if not keep_irrelevant:\n",
    "        work = work[work[\"gain\"] > 0.0]\n",
    "\n",
    "    work = (\n",
    "        work.sort_values([\"gain\"], ascending=False, kind=\"mergesort\")\n",
    "            .drop_duplicates(subset=[query_id_col, product_id_col], keep=\"first\")\n",
    "    )\n",
    "\n",
    "    work = work.sort_values(\n",
    "        by=[query_id_col, \"gain\", product_id_col],\n",
    "        ascending=[True, False, True],\n",
    "        kind=\"mergesort\",\n",
    "    )\n",
    "\n",
    "    if top_k is not None:\n",
    "        work = work.groupby(query_id_col, sort=False, as_index=False).head(top_k)\n",
    "\n",
    "    qrels_df = (\n",
    "        work.groupby(query_id_col, sort=False)[product_id_col]\n",
    "            .apply(list)\n",
    "            .reset_index(name=\"ranked_product_ids\")\n",
    "            .rename(columns={query_id_col: \"query_id\"})\n",
    "    )\n",
    "\n",
    "    qrels_dict: Dict[str, Dict[str, float]] = {}\n",
    "    for qid, sub in work.groupby(query_id_col, sort=False):\n",
    "        qrels_dict[str(qid)] = {str(pid): float(g) for pid, g in zip(sub[product_id_col], sub[\"gain\"])}\n",
    "\n",
    "    return qrels_df, qrels_dict, product_store, query_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f65152",
   "metadata": {},
   "source": [
    "### Build & Save Data artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5be2c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_artifacts(\n",
    "    amz_train_raw: pd.DataFrame,\n",
    "    amz_test_raw: pd.DataFrame,\n",
    "    wands_train_raw: pd.DataFrame,\n",
    "    wands_test_raw: pd.DataFrame\n",
    "):\n",
    "    # Amazon ESCI artifacts\n",
    "    amz_train_qrels_df, amz_train_qrels_dict, amz_train_product_store, amz_train_query_table_df = build_esci_artifacts(amz_train_raw)\n",
    "    amz_test_qrels_df, amz_test_qrels_dict, amz_test_product_store, amz_test_query_table_df = build_esci_artifacts(amz_test_raw)\n",
    "\n",
    "    # WANDS artifacts\n",
    "    wands_train_qrels_df, wands_train_qrels_dict, wands_train_product_store, wands_train_query_table_df = build_wands_artifacts(wands_train_raw)\n",
    "    wands_test_qrels_df, wands_test_qrels_dict, wands_test_product_store, wands_test_query_table_df = build_wands_artifacts(wands_test_raw)\n",
    "    \n",
    "    # Combine product stores for unified access\n",
    "    product_store = amz_train_product_store | amz_test_product_store | wands_train_product_store | wands_test_product_store\n",
    "    \n",
    "    # Combine train and test query tables\n",
    "    train_qrels_df = pd.concat([amz_train_qrels_df, wands_train_qrels_df], ignore_index=True)\n",
    "    test_qrels_df = pd.concat([amz_test_qrels_df, wands_test_qrels_df], ignore_index=True)\n",
    "    \n",
    "    train_qrels_dict = {**amz_train_qrels_dict, **wands_train_qrels_dict}\n",
    "    test_qrels_dict = {**amz_test_qrels_dict, **wands_test_qrels_dict}\n",
    "    \n",
    "    train_query_table_df = pd.concat([amz_train_query_table_df, wands_train_query_table_df], ignore_index=True)\\\n",
    "                             .drop_duplicates(subset=[\"query_id\"], keep=\"first\")\\\n",
    "                             .reset_index(drop=True)\n",
    "    test_query_table_df = pd.concat([amz_test_query_table_df, wands_test_query_table_df], ignore_index=True)\\\n",
    "                            .drop_duplicates(subset=[\"query_id\"], keep=\"first\")\\\n",
    "                            .reset_index(drop=True)\n",
    "    \n",
    "    return {\n",
    "        \"train_qrels_df\": train_qrels_df,\n",
    "        \"test_qrels_df\": test_qrels_df,\n",
    "        \"train_qrels_dict\": train_qrels_dict,\n",
    "        \"test_qrels_dict\": test_qrels_dict,\n",
    "        \"train_query_table_df\": train_query_table_df,\n",
    "        \"test_query_table_df\": test_query_table_df,\n",
    "        \"product_store\": product_store,\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e55729a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = build_data_artifacts(\n",
    "    amz_esci_train_df_raw,\n",
    "    amz_esci_test_df_raw,\n",
    "    wands_train_df_raw,\n",
    "    wands_test_df_raw\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save product store\n",
    "with open(processed_dir / \"product_store.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifacts[\"product_store\"], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save train qrels dict\n",
    "with open(processed_dir / \"train_qrels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifacts[\"train_qrels_dict\"], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(processed_dir / \"test_qrels.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifacts[\"test_qrels_dict\"], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save qrels and query tables as parquet\n",
    "artifacts['train_qrels_df'].to_parquet(\n",
    "    processed_dir / \"train_qrels.parquet\", \n",
    "    index=False, compression='gzip'\n",
    "    )\n",
    "artifacts['test_qrels_df'].to_parquet(\n",
    "    processed_dir / \"test_qrels.parquet\", \n",
    "    index=False, compression='gzip'\n",
    "    )\n",
    "\n",
    "artifacts['train_query_table_df'].to_parquet(\n",
    "    processed_dir / \"train_query_table.parquet\", \n",
    "    index=False, compression='gzip'\n",
    "    )\n",
    "artifacts['test_query_table_df'].to_parquet(\n",
    "    processed_dir / \"test_query_table.parquet\", \n",
    "    index=False, compression='gzip'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
